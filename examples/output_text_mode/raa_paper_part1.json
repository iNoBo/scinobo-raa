{
 "input_path": "examples/input/raa_paper_part1.txt",
 "text_list": [
  [
   "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n",
   "In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n",
   "We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n",
   "The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n",
   "We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n",
   "Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n",
   "Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research."
  ]
 ],
 "research_artifacts": {
  "candidates_metadata": {
   "C0": {
    "type": "software",
    "indices": [
     0,
     1
    ],
    "trigger": "approach",
    "trigger_offset": [
     33,
     41
    ],
    "snippet": "In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n",
    "snippet_offset": [
     162,
     324
    ],
    "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "citations": [
     [],
     [],
     [],
     [],
     []
    ],
    "results": {
     "artifact_answer": {
      "Yes": 0.44089152513714225,
      "No": 0.5591084748628578
     }
    }
   },
   "C1": {
    "type": "dataset",
    "indices": [
     0,
     1
    ],
    "trigger": "dataset",
    "trigger_offset": [
     97,
     104
    ],
    "snippet": "In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n",
    "snippet_offset": [
     162,
     324
    ],
    "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "citations": [
     [],
     [],
     [],
     [],
     []
    ],
    "results": {
     "artifact_answer": {
      "Yes": 0.7509810198362034,
      "No": 0.24901898016379667
     },
     "name_answer": "N/A",
     "license_answer": "N/A",
     "version_answer": "N/A",
     "url_answer": "N/A",
     "ownership_answer": {
      "Yes": 0.036607427796896026,
      "No": 0.9633925722031039
     },
     "ownership_answer_text": "No",
     "reuse_answer": {
      "Yes": 0.5754049720259755,
      "No": 0.4245950279740245
     },
     "reuse_answer_text": "Yes"
    },
    "closest_citation": null
   },
   "C2": {
    "type": "software",
    "indices": [
     0,
     1
    ],
    "trigger": "software",
    "trigger_offset": [
     114,
     122
    ],
    "snippet": "In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n",
    "snippet_offset": [
     162,
     324
    ],
    "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "citations": [
     [],
     [],
     [],
     [],
     []
    ],
    "results": {
     "artifact_answer": {
      "Yes": 0.479832163167191,
      "No": 0.520167836832809
     }
    }
   },
   "C3": {
    "type": "dataset",
    "indices": [
     0,
     2
    ],
    "trigger": "dataset",
    "trigger_offset": [
     29,
     36
    ],
    "snippet": "We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n",
    "snippet_offset": [
     326,
     570
    ],
    "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "citations": [
     [],
     [],
     [],
     [],
     []
    ],
    "results": {
     "artifact_answer": {
      "Yes": 0.9994140660794871,
      "No": 0.0005859339205128863
     },
     "name_answer": "N/A",
     "license_answer": "N/A",
     "version_answer": "N/A",
     "url_answer": "N/A",
     "ownership_answer": {
      "Yes": 0.9968132435341908,
      "No": 0.003186756465809213
     },
     "ownership_answer_text": "Yes",
     "reuse_answer": {
      "Yes": 0.0545057220363447,
      "No": 0.9454942779636553
     },
     "reuse_answer_text": "No"
    },
    "closest_citation": null
   },
   "C4": {
    "type": "software",
    "indices": [
     0,
     2
    ],
    "trigger": "process",
    "trigger_offset": [
     235,
     242
    ],
    "snippet": "We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n",
    "snippet_offset": [
     326,
     570
    ],
    "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "citations": [
     [],
     [],
     [],
     [],
     []
    ],
    "results": {
     "artifact_answer": {
      "Yes": 0.9918162683286142,
      "No": 0.00818373167138571
     },
     "name_answer": "N/A",
     "license_answer": "N/A",
     "version_answer": "N/A",
     "url_answer": "N/A",
     "ownership_answer": {
      "Yes": 0.5185490387473942,
      "No": 0.4814509612526057
     },
     "ownership_answer_text": "Yes",
     "reuse_answer": {
      "Yes": 0.8111544725826685,
      "No": 0.1888455274173315
     },
     "reuse_answer_text": "Yes"
    },
    "closest_citation": null
   },
   "C5": {
    "type": "dataset",
    "indices": [
     0,
     3
    ],
    "trigger": "dataset",
    "trigger_offset": [
     4,
     11
    ],
    "snippet": "The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n",
    "snippet_offset": [
     572,
     813
    ],
    "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "citations": [
     [],
     [],
     [],
     [],
     []
    ],
    "results": {
     "artifact_answer": {
      "Yes": 0.9993942580981334,
      "No": 0.0006057419018665689
     },
     "name_answer": "N/A",
     "license_answer": "N/A",
     "version_answer": "N/A",
     "url_answer": "N/A",
     "ownership_answer": {
      "Yes": 0.012982038768583597,
      "No": 0.9870179612314164
     },
     "ownership_answer_text": "No",
     "reuse_answer": {
      "Yes": 0.09339588302281032,
      "No": 0.9066041169771897
     },
     "reuse_answer_text": "No"
    }
   },
   "C6": {
    "type": "dataset",
    "indices": [
     0,
     3
    ],
    "trigger": "dataset",
    "trigger_offset": [
     93,
     100
    ],
    "snippet": "The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n",
    "snippet_offset": [
     572,
     813
    ],
    "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "citations": [
     [],
     [],
     [],
     [],
     []
    ],
    "results": {
     "artifact_answer": {
      "Yes": 0.9934774781526362,
      "No": 0.006522521847363754
     },
     "name_answer": "N/A",
     "license_answer": "N/A",
     "version_answer": "N/A",
     "url_answer": "N/A",
     "ownership_answer": {
      "Yes": 0.006493545719533928,
      "No": 0.993506454280466
     },
     "ownership_answer_text": "No",
     "reuse_answer": {
      "Yes": 0.16665217480253522,
      "No": 0.8333478251974648
     },
     "reuse_answer_text": "No"
    }
   },
   "C7": {
    "type": "software",
    "indices": [
     0,
     3
    ],
    "trigger": "software",
    "trigger_offset": [
     110,
     118
    ],
    "snippet": "The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n",
    "snippet_offset": [
     572,
     813
    ],
    "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "citations": [
     [],
     [],
     [],
     [],
     []
    ],
    "results": {
     "artifact_answer": {
      "Yes": 0.9932121801507545,
      "No": 0.0067878198492454375
     },
     "name_answer": "N/A",
     "license_answer": "N/A",
     "version_answer": "N/A",
     "url_answer": "N/A",
     "ownership_answer": {
      "Yes": 0.22073437835577242,
      "No": 0.7792656216442275
     },
     "ownership_answer_text": "No",
     "reuse_answer": {
      "Yes": 0.7513829197682341,
      "No": 0.24861708023176593
     },
     "reuse_answer_text": "Yes"
    }
   },
   "C8": {
    "type": "software",
    "indices": [
     0,
     4
    ],
    "trigger": "model",
    "trigger_offset": [
     42,
     47
    ],
    "snippet": "We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n",
    "snippet_offset": [
     815,
     1008
    ],
    "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "citations": [
     [],
     [],
     [],
     [],
     []
    ],
    "results": {
     "artifact_answer": {
      "Yes": 0.9998809672547632,
      "No": 0.00011903274523694774
     },
     "name_answer": "LLM",
     "license_answer": "N/A",
     "version_answer": "N/A",
     "url_answer": "N/A",
     "ownership_answer": {
      "Yes": 0.25536068780113347,
      "No": 0.7446393121988665
     },
     "ownership_answer_text": "No",
     "reuse_answer": {
      "Yes": 0.9875792702476798,
      "No": 0.012420729752320217
     },
     "reuse_answer_text": "Yes"
    },
    "closest_citation": null
   },
   "C9": {
    "type": "dataset",
    "indices": [
     0,
     5
    ],
    "trigger": "dataset",
    "trigger_offset": [
     77,
     84
    ],
    "snippet": "Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n",
    "snippet_offset": [
     1010,
     1135
    ],
    "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "citations": [
     [],
     [],
     [],
     [],
     []
    ],
    "results": {
     "artifact_answer": {
      "Yes": 0.9997100747613309,
      "No": 0.00028992523866914934
     },
     "name_answer": "N/A",
     "license_answer": "N/A",
     "version_answer": "N/A",
     "url_answer": "N/A",
     "ownership_answer": {
      "Yes": 0.9986090633972198,
      "No": 0.0013909366027802126
     },
     "ownership_answer_text": "Yes",
     "reuse_answer": {
      "Yes": 0.9935880466680683,
      "No": 0.006411953331931656
     },
     "reuse_answer_text": "Yes"
    }
   },
   "C10": {
    "type": "gaz_method",
    "indices": [
     0,
     5
    ],
    "trigger": "BASE",
    "trigger_offset": [
     108,
     112
    ],
    "snippet": "Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n",
    "snippet_offset": [
     1010,
     1135
    ],
    "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "citations": [
     [],
     [],
     [],
     [],
     []
    ],
    "results": {
     "artifact_answer": {
      "Yes": 0.5098059768025658,
      "No": 0.49019402319743416
     },
     "name_answer": "LLM",
     "license_answer": "N/A",
     "version_answer": "N/A",
     "url_answer": "N/A",
     "ownership_answer": {
      "Yes": 0.00198594773744973,
      "No": 0.9980140522625502
     },
     "ownership_answer_text": "No",
     "reuse_answer": {
      "Yes": 0.8905491632829354,
      "No": 0.10945083671706458
     },
     "reuse_answer_text": "Yes"
    },
    "closest_citation": null
   },
   "C11": {
    "type": "software",
    "indices": [
     0,
     5
    ],
    "trigger": "models",
    "trigger_offset": [
     117,
     123
    ],
    "snippet": "Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n",
    "snippet_offset": [
     1010,
     1135
    ],
    "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "citations": [
     [],
     [],
     [],
     [],
     []
    ],
    "results": {
     "artifact_answer": {
      "Yes": 0.9036010274388864,
      "No": 0.09639897256111367
     },
     "name_answer": "LLM",
     "license_answer": "N/A",
     "version_answer": "N/A",
     "url_answer": "N/A",
     "ownership_answer": {
      "Yes": 0.0018612534871055263,
      "No": 0.9981387465128945
     },
     "ownership_answer_text": "No",
     "reuse_answer": {
      "Yes": 0.9295786602701102,
      "No": 0.0704213397298899
     },
     "reuse_answer_text": "Yes"
    },
    "closest_citation": null
   },
   "C12": {
    "type": "software",
    "indices": [
     0,
     6
    ],
    "trigger": "method",
    "trigger_offset": [
     4,
     10
    ],
    "snippet": "Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "snippet_offset": [
     1137,
     1381
    ],
    "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "citations": [
     [],
     [],
     [],
     [],
     []
    ],
    "results": {
     "artifact_answer": {
      "Yes": 0.9992001234951842,
      "No": 0.0007998765048158286
     },
     "name_answer": "N/A",
     "license_answer": "N/A",
     "version_answer": "N/A",
     "url_answer": "N/A",
     "ownership_answer": {
      "Yes": 0.9984561410013051,
      "No": 0.0015438589986949676
     },
     "ownership_answer_text": "Yes",
     "reuse_answer": {
      "Yes": 0.4467696084219917,
      "No": 0.5532303915780084
     },
     "reuse_answer_text": "No"
    }
   },
   "C13": {
    "type": "dataset",
    "indices": [
     0,
     6
    ],
    "trigger": "datasets",
    "trigger_offset": [
     109,
     117
    ],
    "snippet": "Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "snippet_offset": [
     1137,
     1381
    ],
    "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "citations": [
     [],
     [],
     [],
     [],
     []
    ],
    "results": {
     "artifact_answer": {
      "Yes": 0.02949364698579359,
      "No": 0.9705063530142064
     }
    }
   },
   "C14": {
    "type": "software",
    "indices": [
     0,
     6
    ],
    "trigger": "software",
    "trigger_offset": [
     122,
     130
    ],
    "snippet": "Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "snippet_offset": [
     1137,
     1381
    ],
    "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
    "citations": [
     [],
     [],
     [],
     [],
     []
    ],
    "results": {
     "artifact_answer": {
      "Yes": 0.003947284579902294,
      "No": 0.9960527154200977
     }
    }
   }
  },
  "grouped_clusters": {
   "dataset": {
    "name_cluster_0": {},
    "Unnamed": {
     "Unnamed_3": [
      [
       "C3",
       {
        "type": "dataset",
        "indices": [
         0,
         2
        ],
        "trigger": "dataset",
        "trigger_offset": [
         29,
         36
        ],
        "snippet": "We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n",
        "snippet_offset": [
         326,
         570
        ],
        "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
        "citations": [
         [],
         [],
         [],
         [],
         []
        ],
        "results": {
         "artifact_answer": {
          "Yes": 0.9994140660794871,
          "No": 0.0005859339205128863
         },
         "name_answer": "N/A",
         "license_answer": "N/A",
         "version_answer": "N/A",
         "url_answer": "N/A",
         "ownership_answer": {
          "Yes": 0.9968132435341908,
          "No": 0.003186756465809213
         },
         "ownership_answer_text": "Yes",
         "reuse_answer": {
          "Yes": 0.0545057220363447,
          "No": 0.9454942779636553
         },
         "reuse_answer_text": "No"
        },
        "closest_citation": null
       },
       "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive <m>dataset</m>, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n\n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research."
      ]
     ],
     "Unnamed_4": [
      [
       "C1",
       {
        "type": "dataset",
        "indices": [
         0,
         1
        ],
        "trigger": "dataset",
        "trigger_offset": [
         97,
         104
        ],
        "snippet": "In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n",
        "snippet_offset": [
         162,
         324
        ],
        "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
        "citations": [
         [],
         [],
         [],
         [],
         []
        ],
        "results": {
         "artifact_answer": {
          "Yes": 0.7509810198362034,
          "No": 0.24901898016379667
         },
         "name_answer": "N/A",
         "license_answer": "N/A",
         "version_answer": "N/A",
         "url_answer": "N/A",
         "ownership_answer": {
          "Yes": 0.036607427796896026,
          "No": 0.9633925722031039
         },
         "ownership_answer_text": "No",
         "reuse_answer": {
          "Yes": 0.5754049720259755,
          "No": 0.4245950279740245
         },
         "reuse_answer_text": "Yes"
        },
        "closest_citation": null
       },
       "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of <m>dataset</m> and code/software mentions within scientific literature. \n\n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research."
      ]
     ]
    }
   },
   "software": {
    "name_cluster_0": {
     "LLM": [
      [
       "C8",
       {
        "type": "software",
        "indices": [
         0,
         4
        ],
        "trigger": "model",
        "trigger_offset": [
         42,
         47
        ],
        "snippet": "We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n",
        "snippet_offset": [
         815,
         1008
        ],
        "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
        "citations": [
         [],
         [],
         [],
         [],
         []
        ],
        "results": {
         "artifact_answer": {
          "Yes": 0.9998809672547632,
          "No": 0.00011903274523694774
         },
         "name_answer": "LLM",
         "license_answer": "N/A",
         "version_answer": "N/A",
         "url_answer": "N/A",
         "ownership_answer": {
          "Yes": 0.25536068780113347,
          "No": 0.7446393121988665
         },
         "ownership_answer_text": "No",
         "reuse_answer": {
          "Yes": 0.9875792702476798,
          "No": 0.012420729752320217
         },
         "reuse_answer_text": "Yes"
        },
        "closest_citation": null
       },
       "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language <m>Model</m> (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n\n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research."
      ],
      [
       "C10",
       {
        "type": "gaz_method",
        "indices": [
         0,
         5
        ],
        "trigger": "BASE",
        "trigger_offset": [
         108,
         112
        ],
        "snippet": "Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n",
        "snippet_offset": [
         1010,
         1135
        ],
        "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
        "citations": [
         [],
         [],
         [],
         [],
         []
        ],
        "results": {
         "artifact_answer": {
          "Yes": 0.5098059768025658,
          "No": 0.49019402319743416
         },
         "name_answer": "LLM",
         "license_answer": "N/A",
         "version_answer": "N/A",
         "url_answer": "N/A",
         "ownership_answer": {
          "Yes": 0.00198594773744973,
          "No": 0.9980140522625502
         },
         "ownership_answer_text": "No",
         "reuse_answer": {
          "Yes": 0.8905491632829354,
          "No": 0.10945083671706458
         },
         "reuse_answer_text": "Yes"
        },
        "closest_citation": null
       },
       "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other <m>base</m> LLM models. \n\n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research."
      ],
      [
       "C11",
       {
        "type": "software",
        "indices": [
         0,
         5
        ],
        "trigger": "models",
        "trigger_offset": [
         117,
         123
        ],
        "snippet": "Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n",
        "snippet_offset": [
         1010,
         1135
        ],
        "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
        "citations": [
         [],
         [],
         [],
         [],
         []
        ],
        "results": {
         "artifact_answer": {
          "Yes": 0.9036010274388864,
          "No": 0.09639897256111367
         },
         "name_answer": "LLM",
         "license_answer": "N/A",
         "version_answer": "N/A",
         "url_answer": "N/A",
         "ownership_answer": {
          "Yes": 0.0018612534871055263,
          "No": 0.9981387465128945
         },
         "ownership_answer_text": "No",
         "reuse_answer": {
          "Yes": 0.9295786602701102,
          "No": 0.0704213397298899
         },
         "reuse_answer_text": "Yes"
        },
        "closest_citation": null
       },
       "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM <m>models</m>. \n\n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research."
      ]
     ]
    },
    "Unnamed": {
     "Unnamed_2": [
      [
       "C4",
       {
        "type": "software",
        "indices": [
         0,
         2
        ],
        "trigger": "process",
        "trigger_offset": [
         235,
         242
        ],
        "snippet": "We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n",
        "snippet_offset": [
         326,
         570
        ],
        "paragraph": "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop process. \n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research.",
        "citations": [
         [],
         [],
         [],
         [],
         []
        ],
        "results": {
         "artifact_answer": {
          "Yes": 0.9918162683286142,
          "No": 0.00818373167138571
         },
         "name_answer": "N/A",
         "license_answer": "N/A",
         "version_answer": "N/A",
         "url_answer": "N/A",
         "ownership_answer": {
          "Yes": 0.5185490387473942,
          "No": 0.4814509612526057
         },
         "ownership_answer_text": "Yes",
         "reuse_answer": {
          "Yes": 0.8111544725826685,
          "No": 0.1888455274173315
         },
         "reuse_answer_text": "Yes"
        },
        "closest_citation": null
       },
       "Knowledge extraction from scientific literature is a major issue, crucial to promoting transparency, reproducibility, and innovation in the research community. \n In this work, we present a novel approach towards the identification, extraction and analysis of dataset and code/software mentions within scientific literature. \n We introduce a comprehensive dataset, synthetically generated by ChatGPT and meticulously curated, augmented, and expanded with real snippets of scientific text from full-text publications in Computer Science using a human-in-the-loop <m>process</m>. \n\n The dataset contains snippets highlighting mentions of the two research artifact (RA) types: dataset and code/software, along with insightful metadata including their Name, Version, License, URL as well as the intended Usage and Provenance. \n We also fine-tune a simple Large Language Model (LLM) using Low-Rank Adaptation (LoRA) to transform the Research Artifact Analysis (RAA) into an instruction-based Question Answering (QA) task. \n Ultimately, we report the improvements in performance on the test set of our dataset when compared to other base LLM models. \n Our method provides a significant step towards facilitating accurate, effective, and efficient extraction of datasets and software from scientific papers, contributing to the challenges of reproducibility and reusability in scientific research."
      ]
     ]
    }
   }
  }
 }
}